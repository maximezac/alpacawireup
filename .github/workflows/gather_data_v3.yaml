name: Gather Data (ideas only, no trades)

on:
  workflow_dispatch:
  push:
    paths:
      - "data/symbols.txt"
      - "fetch_prices.py"
      - "publish_feed.py"
      - "fetch_news.py"
      - "scripts/**"
      - ".github/workflows/**"
      - "requirements.txt"
      - "artifacts/**"
  schedule:
    - cron: "0 * * * 1-5"

permissions:
  contents: write

env:
  INPUT_BASE: data/prices.json
  INPUT_FINAL: data/prices_final.json

concurrency:
  group: gather-data-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-run-publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Set up Python
        uses: actions/setup-python@v5
        with: { python-version: "3.11" }

      - name: Install dependencies
        run: |
          which python
          python -m pip install --upgrade pip
          pip install pandas==2.2.2 numpy==1.26.4 requests==2.32.3 \
                      python-dateutil==2.9.0.post0 feedparser==6.0.11 \
                      vaderSentiment==3.3.2 pyyaml==6.0.2
          pip install -r requirements.txt || echo "requirements.txt already satisfied."
      
      - name: Probe freshness
        id: probe
        shell: bash
        run: |
          set -euo pipefail
      
          is_fresh_file() {
            local f="$1" max_age_hours="$2"
            [ -f "$f" ] || { echo "false"; return; }
            # prefer as_of_utc if present; else use mtime
            if jq -e 'has("as_of_utc")' "$f" >/dev/null 2>&1; then
              ts=$(jq -r '.as_of_utc' "$f" | sed 's/Z$/+00:00/')
              # seconds since file timestamp
              now=$(date -u +%s)
              file=$(date -u -d "$ts" +%s 2>/dev/null || echo 0)
              age=$(( (now - file) / 3600 ))
            else
              mtime=$(date -u -r "$f" +%s)
              now=$(date -u +%s)
              age=$(( (now - mtime) / 3600 ))
            fi
            if [ "$age" -le "$max_age_hours" ]; then echo "true"; else echo "false"; fi
          }
      
          FRESH_PRICES=$(is_fresh_file "${INPUT_BASE}" 6)
          FRESH_BASE=$(is_fresh_file "${INPUT_BASE}" 24)   # for news lookback gate
      
          echo "fresh_prices=$FRESH_PRICES" | tee -a "$GITHUB_OUTPUT"
          echo "fresh_base=$FRESH_BASE"     | tee -a "$GITHUB_OUTPUT"


      - name: Fetch prices (if stale)
        if: steps.probe.outputs.fresh_prices != 'true'
        env:
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          ALPACA_DATA_FEED:  iex
          SYMBOLS_PATH:      data/symbols.txt
          OUTPUT_PATH:       data/prices.json
          DAYS_BACK:         "270"
        run: python fetch_prices.py

      - name: Fetch news (if stale)
        if: steps.probe.outputs.fresh_base != 'true'
        env:
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          INPUT_PATH:        data/prices.json
          OUTPUT_PATH:       data/prices.json
          NEWS_LOOKBACK_DAYS: "7"
          NEWS_LIMIT_PER_SYMBOL: "25"
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
          FINNHUB_KEY: ${{ secrets.FINNHUB_KEY }}
          NEWS_SOURCES: "benzinga,mtnewswires,google_rss,finnhub,reddit"
        run: python fetch_news.py

      - name: Generate enriched feed
        env:
          INPUT_PATH:  data/prices.json
          OUTPUT_PATH: data/prices_final.json
          MAX_ARTICLES: "15"
          DECAY_HALF_LIFE_HOURS: "12"
          SECTOR_NUDGE: "0.05"
          GENERATE_NOW: "1"
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
        run: python publish_feed.py

      - name: Postprocess (multi-portfolio ideas; no execution)
        env:
          INPUT_FINAL:      data/prices_final.json
          PORTFOLIOS_YML:   artifacts/portfolios.yaml
          OUT_WATCHLIST:    data/watchlist_summary.json
          OUT_TRADES:       artifacts/recommended_trades_v3.json
        run: |
          mkdir -p artifacts
          which python
          python -m pip show pyyaml
          python scripts/postprocess_v3.py
          printf '%s\n' \
            'import json,sys' \
            'p="artifacts/recommended_trades_v3.json"' \
            'try:' \
            '    with open(p) as f: obj=json.load(f)' \
            '    ports=obj.get("portfolios") or {}' \
            '    tot=0' \
            '    for name,node in ports.items():' \
            '        m=len(node.get("trades") or [])' \
            '        print(f"- {name}: {m} trades")' \
            '        tot+=m' \
            '    print("TOTAL TRADES:", tot)' \
            'except Exception as e:' \
            '    print("summarize trades failed:", e, file=sys.stderr)' \
          > /tmp/summarize_trades.py
          python /tmp/summarize_trades.py

      - name: Snapshots (no trades)
        env:
          PRICES_FINAL:   data/prices_final.json
          TRADES_RECS:    artifacts/recommended_trades_v3.json   # <-- same file executor reads
          TRADES_LEDGER:  data/trades_ledger.csv
          APPLY_TRADES:   "0"
        run: python scripts/update_performance_v3.py

      - name: Commit & push
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git pull --rebase --autostash origin ${{ github.ref_name }}
          git add data/*.json data/*history.csv data/trades_ledger.csv \
                  artifacts/*.yaml artifacts/*.json || true
          git commit -m "v3: ideas-only refresh (multi-portfolio)" || echo "No changes."
          git push
