name: Gather Data (ideas only, no trades)

on:
  workflow_dispatch:
  push:
    paths:
      - "data/symbols.txt"
      - "fetch_prices.py"
      - "publish_feed.py"
      - "fetch_news.py"
      - "scripts/**"
      - ".github/workflows/**"
      - "requirements.txt"
      - "artifacts/**"
  schedule:
    - cron: "0 * * * 1-5"

permissions:
  contents: write

env:
  INPUT_BASE: data/prices.json
  INPUT_FINAL: data/prices_final.json
  PORTFOLIOS_YML: config/portfolios.yml
  OUT_TRADES: artifacts/recommended_trades_v3.json
  OUT_WATCHLIST: data/watchlist_summary.json
  # Optional: reduce clutter from versioned artifacts created by scripts
  V3_DISABLE_VERSIONED_ARTIFACTS: "1"

concurrency:
  group: gather-data-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-run-publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Set up Python
        uses: actions/setup-python@v5
        with: { python-version: "3.11" }

      - name: Install dependencies
        run: |
          which python
          python -m pip install --upgrade pip
          pip install pandas==2.2.2 numpy==1.26.4 requests==2.32.3 \
                      python-dateutil==2.9.0.post0 feedparser==6.0.11 \
                      vaderSentiment==3.3.2 pyyaml==6.0.2
          pip install -r requirements.txt || echo "requirements.txt already satisfied."

      - name: Ensure jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Export PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> "$GITHUB_ENV"

      - name: Probe freshness
        id: probe
        shell: bash
        run: |
          set -euo pipefail
          is_fresh_file() {
            local f="$1" max_age_hours="$2"
            [ -f "$f" ] || { echo "false"; return; }
            if jq -e 'has("as_of_utc")' "$f" >/dev/null 2>&1; then
              ts=$(jq -r '.as_of_utc' "$f" | sed 's/Z$/+00:00/')
              now=$(date -u +%s)
              file=$(date -u -d "$ts" +%s 2>/dev/null || echo 0)
              age=$(( (now - file) / 3600 ))
            else
              mtime=$(date -u -r "$f" +%s)
              now=$(date -u +%s)
              age=$(( (now - mtime) / 3600 ))
            fi
            if [ "$age" -le "$max_age_hours" ]; then echo "true"; else echo "false"; fi
          }
          echo "fresh_prices=$(is_fresh_file '${INPUT_BASE}' 6)"  | tee -a "$GITHUB_OUTPUT"
          echo "fresh_base=$(is_fresh_file '${INPUT_BASE}' 24)"   | tee -a "$GITHUB_OUTPUT"

      - name: Fetch prices (if stale)
        if: steps.probe.outputs.fresh_prices != 'true'
        env:
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          ALPACA_DATA_FEED:  iex
          SYMBOLS_PATH:      data/symbols.txt
          OUTPUT_PATH:       data/prices.json
          DAYS_BACK:         "270"
        run: python fetch_prices.py

      - name: Set WEEKDAY
        run: echo "WEEKDAY=$(date -u +%a)" >> "$GITHUB_ENV"

      - name: Fetch news (weekday always)
        if: contains('Mon Tue Wed Thu Fri', env.WEEKDAY)
        continue-on-error: true
        env:
          INPUT_PATH:  data/prices.json
          OUTPUT_PATH: data/prices.json
          NEWS_LOOKBACK_DAYS: "7"
          NEWS_LIMIT_PER_SYMBOL: "25"
          NEWS_SOURCES: "benzinga,mtnewswires,google_rss,finnhub,reddit"
          NEWSAPI_KEY:  ${{ secrets.NEWSAPI_KEY }}
          FINNHUB_KEY:  ${{ secrets.FINNHUB_KEY }}
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          USE_FINBERT: "1"
          FINBERT_TRIGGER: "0.20"
          FINBERT_FRACTION: "0.30"
        run: python scripts/fetch_news.py

      - name: Generate enriched feed
        env:
          INPUT_PATH:  data/prices.json
          OUTPUT_PATH: data/prices_final.json
          MAX_ARTICLES: "15"
          DECAY_HALF_LIFE_HOURS: "12"
          SECTOR_NUDGE: "0.05"
          GENERATE_NOW: "1"
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
        run: python publish_feed.py

      - name: Quick stats
        run: |
          echo "as_of_utc:" $(jq -r '.as_of_utc' data/prices_final.json)
          echo "symbols:"   $(jq '.symbols|keys|length' data/prices_final.json)
          echo "news items in base:" $(jq '[.symbols[]|.news?|length]|add' data/prices.json)

      - name: Postprocess (plans only; NO execution)
        env:
          INPUT_FINAL:        data/prices_final.json
          PORTFOLIOS_YML:     config/portfolios.yml
          OUT_WATCHLIST:      data/watchlist_summary.json
          OUT_TRADES:         artifacts/recommended_trades_v3.json
        run: |
          python scripts/postprocess_v3.py
          python - <<'PY'
          import json,sys
          try:
              obj=json.load(open("artifacts/recommended_trades_v3.json"))
              total=0
              for name,node in (obj.get("portfolios") or {}).items():
                  n=len(node.get("trades") or [])
                  print(f"- {name}: {n} trades")
                  total+=n
              print("TOTAL TRADES:", total)
          except Exception as e:
              print("summarize trades failed:", e, file=sys.stderr)
          PY

      # NOTE: no update_performance_v3.py here (that can mark last_applied and block real execution)

      - name: Commit & push (ideas only)
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git pull --rebase --autostash origin ${{ github.ref_name }}
          git add data/*.json artifacts/*.json data/watchlist_summary.json || true
          git commit -m "v3: ideas-only refresh (multi-portfolio)" || echo "No changes."
          git push
