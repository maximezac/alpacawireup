name: Backtest Strategy v3
on:
  workflow_dispatch:
    inputs:
      start_date:
        description: "Backtest start date (YYYY-MM-DD)"
        required: true
        type: string
      end_date:
        description: "Backtest end date (YYYY-MM-DD)"
        required: true
        type: string
      step_days:
        description: "Step size in days between snapshots"
        required: false
        default: "5"
        type: string
      experiment_id:
        description: "Experiment label (for summaries)"
        required: false
        default: "exp_v1"
        type: string
      apply_trades:
        description: "Apply trades (1) or dry-run (0)"
        required: false
        default: "0"
        type: string
      backtest_half_life_hours:
        description: "Backtest half-life hours (overrides default)"
        required: false
        default: "336"
        type: string
      backtest_ns_max_age_days:
        description: "Backtest news max age days (overrides default)"
        required: false
        default: "90"
        type: string

permissions:
  contents: read

jobs:
  backtest:
    runs-on: ubuntu-latest
    env:
      # Backtest reads from the per-step snapshot feed
      BACKTEST_PRICES_FINAL: data/prices_final_snapshot.json
      PRICES_FINAL:           data/prices_final_snapshot.json
      # Where postprocess_v3 writes its recommended trades
      TRADES_RECS:            artifacts/recommended_trades_v3.json
      BACKTEST_TRADES_PATH:   artifacts/recommended_trades_v3.json
      # Backtest-specific global ledger
      TRADES_LEDGER:          data/trades_ledger_backtest.csv
      BACKTEST_TRADES_LEDGER: data/trades_ledger_backtest.csv
      # Engine configs (adjust to match your existing gather workflow)
      CONFIG_PORTFOLIOS: config/portfolios.yml
      CONFIG_STRATEGIES: config/strategies.yml
      OUTPUT_DIR:         artifacts
      # Only execute paper portfolios by default
      EXECUTE_SCOPE: paper
      EXECUTE_TAGS: backtest        # e.g. "backtest" if you tag certain portfolios
      # Disable versioned per-snapshot artifacts for backtesting to avoid bloat
      # This prevents update_performance_v3 from writing portfolio_value_<ts>.json snapshots
      ARTIFACT_VERSIONED: "false"
      V3_DISABLE_VERSIONED_ARTIFACTS: "1"
      # Keep APPLY_TRADES configurable
      APPLY_TRADES: "${{ inputs.apply_trades }}"
      BACKTEST_NS_MAX_AGE_DAYS : 90

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas==2.2.2 numpy==1.26.4 requests==2.32.3 \
            python-dateutil==2.9.0.post0 feedparser==6.0.11 \
            vaderSentiment==3.3.2 pyyaml==6.0.2 matplotlib==3.8.1
          pip install -r requirements.txt || echo "requirements.txt already satisfied."

      - name: Export PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> "$GITHUB_ENV"

      # ------------------------------------------------------------------
      # 1) Download the backfilled prices + news from previous workflow
      # ------------------------------------------------------------------
      - name: Restore backfill from cache
        id: cache-backfill
        uses: actions/cache@v4
        with:
          path: data/prices_backfill.tar.gz
          key: backfill-v1-${{ hashFiles('data/symbols_backtest.txt') }}

      - name: Extract backfill JSON
        if: steps.cache-backfill.outputs.cache-hit == 'true'
        run: |
          mkdir -p data
          tar -xzf data/prices_backfill.tar.gz -C data
          ls -lh data/prices_backfill.*

      - name: Fail if backfill cache is missing
        if: steps.cache-backfill.outputs.cache-hit != 'true'
        run: |
          echo "ERROR: Backfill cache not found."
          echo "Run the 'Backfill History (prices + news)' workflow once to generate it." >&2
          exit 1

      - name: Sanity check backfill file
        run: |
          python - << 'PY'
          import json, pathlib
          p = pathlib.Path("data/prices_backfill.json")
          print("Backfill exists:", p.exists(), "size MB:", p.stat().st_size / (1024*1024))
          obj = json.loads(p.read_text())
          print("as_of_utc:", obj.get("as_of_utc"))
          syms = obj.get("symbols", {})
          print("symbols:", len(syms))
          samp = next(iter(syms.keys()), None)
          if samp:
            bars = syms[samp].get("bars", [])
            news = syms[samp].get("news", [])
            print("sample:", samp, "bars:", len(bars), "news:", len(news))
          PY

      # ------------------------------------------------------------------
      # 2) Backtest loop: run experiment runner
      # ------------------------------------------------------------------
      - name: Run experiment runner
        env:
          BACKTEST_MODE: "1"
          EXPERIMENT_ID: ${{ inputs.experiment_id }}
          APPLY_TRADES: ${{ inputs.apply_trades }}
          EXECUTE_SCOPE: paper
          BACKTEST_NS_MAX_AGE_DAYS: ${{ inputs.backtest_ns_max_age_days }}
          BACKTEST_HALF_LIFE_HOURS: ${{ inputs.backtest_half_life_hours }}
        run: |
          python scripts/experiment_runner.py --start ${{ inputs.start_date }} --end ${{ inputs.end_date }} --step ${{ inputs.step_days }} --experiment ${{ inputs.experiment_id }}

      # ------------------------------------------------------------------
      # 3) Upload all portfolio histories, per-variant artifacts & ledgers as artifacts
      #    - Debug listing to show exactly what's included
      #    - Zip per-experiment artifacts (recommended)
      #    - Upload artifacts/**, .tmp/**, data/portfolios/** and the listing file
      # ------------------------------------------------------------------
      - name: Ensure helper script is executable
        run: |
          if [ -f scripts/ci/list_artifacts_for_upload.sh ]; then
            chmod +x scripts/ci/list_artifacts_for_upload.sh
          fi

      - name: Remove versioned portfolio_value snapshots (prevent upload)
        run: |
          echo "Removing versioned portfolio_value_*.json files to avoid uploading per-snapshot snapshots"
          find data/portfolios -type f -name 'portfolio_value_*.json' -print -delete || true
          find artifacts -type f -name 'portfolio_value_*.json' -print -delete || true
        shell: bash

      - name: List artifact files to upload (debug)
        run: |
          echo "=== workspace top-level ==="
          ls -la || true
          echo "=== Checking candidate upload paths ==="
          bash scripts/ci/list_artifacts_for_upload.sh artifacts/upload_included_files.txt
          echo "=== File list preview ==="
          sed -n '1,200p' artifacts/upload_included_files.txt

      - name: Zip artifacts folder (optional, recommended)
        run: |
          set -euo pipefail
          EXP_ID="${{ inputs.experiment_id || 'exp_unknown' }}"
          mkdir -p artifacts
          if [ -d "artifacts/${EXP_ID}" ]; then
            zip -r "artifacts/${EXP_ID}.zip" "artifacts/${EXP_ID}" || true
            echo "Created artifacts/${EXP_ID}.zip"
          else
            zip -r "artifacts/${EXP_ID}.zip" artifacts || true
            echo "Created artifacts/${EXP_ID}.zip (fallback to whole artifacts/)"
          fi
        shell: bash

      - name: Show what will be uploaded (debug)
        run: |
          echo "=== artifacts dir listing ==="
          ls -la artifacts || true
          echo "=== artifact zip (if exists) ==="
          ls -la artifacts/*.zip || true
          echo "=== included files listing preview ==="
          [ -f artifacts/upload_included_files.txt ] && sed -n '1,400p' artifacts/upload_included_files.txt || true
        shell: bash

      - name: Upload experiment artifacts (full tree + debug listing)
        uses: actions/upload-artifact@v4
        with:
          name: backtest-results-${{ inputs.experiment_id }}
          path: |
            artifacts/**
            .tmp/**
            data/portfolios/**
            artifacts/upload_included_files.txt
          retention-days: 90