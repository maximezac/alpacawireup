name: Gather + Execute (paper trades on)

on:
  workflow_dispatch:
    inputs:
      dry_run:
        description: "Dry run (no trade execution)"
        required: false
        default: "false"
      apply_personal:
        description: "Also apply trades to personal?"
        required: false
        default: "false"


permissions:
  contents: write

concurrency:
  group: gather-exec-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Set up Python
        uses: actions/setup-python@v5
        with: { python-version: "3.11" }

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas==2.2.2 numpy==1.26.4 requests==2.32.3 \
                      python-dateutil==2.9.0.post0 feedparser==6.0.11 \
                      vaderSentiment==3.3.2 pyyaml==6.0.2 matplotlib==3.9.2
          pip install -r requirements.txt || echo "requirements.txt already satisfied."

      - name: Export PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> "$GITHUB_ENV"

      # ---- ALWAYS fetch prices ----
      - name: Fetch prices (always)
        env:
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          ALPACA_DATA_FEED:  iex
          SYMBOLS_PATH:      data/symbols.txt
          OUTPUT_PATH:       data/prices.json
          DAYS_BACK:         "270"
        run: python fetch_prices.py

      # (Optional) keep news conditional, or remove the if to always fetch news too
      - name: Fetch news (lways or keep stale-check)
        env:
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          INPUT_PATH:        data/prices.json
          OUTPUT_PATH:       data/prices.json
          NEWS_LOOKBACK_DAYS: "7"
          NEWS_LIMIT_PER_SYMBOL: "25"
          NEWS_SOURCES: "benzinga,mtnewswires,google_rss,finnhub,reddit"
          NEWSAPI_KEY:       ${{ secrets.NEWSAPI_KEY }}
          FINNHUB_KEY:       ${{ secrets.FINNHUB_KEY }}
        run: python scripts/fetch_news.py

      - name: Generate enriched feed
        env:
          INPUT_PATH:  data/prices.json
          OUTPUT_PATH: data/prices_final.json
          MAX_ARTICLES: "15"
          DECAY_HALF_LIFE_HOURS: "12"
          SECTOR_NUDGE: "0.05"
          GENERATE_NOW: "1"
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
        run: python publish_feed.py

      - name: Postprocess (build multi-portfolio plans)
        env:
          INPUT_FINAL:        data/prices_final.json
          PORTFOLIOS_YML:     config/portfolios.yml
          OUT_WATCHLIST:      data/watchlist_summary.json
          OUT_TRADES:         artifacts/recommended_trades_v3.json
        run: |
          python scripts/postprocess_v3.py
          python - <<'PY'
          import json,sys
          try:
              obj=json.load(open("artifacts/recommended_trades_v3.json"))
              total=0
              for name,node in (obj.get("portfolios") or {}).items():
                  n=len(node.get("trades") or [])
                  print(f"- {name}: {n} trades"); total+=n
              print("TOTAL TRADES:", total)
          except Exception as e:
              print("summarize trades failed:", e, file=sys.stderr)
          PY

      - name: Check snapshot idempotency
        id: idem
        shell: bash
        run: |
          python - <<'PY'
          import os,json,sys
          from pathlib import Path
          state=Path("data/_applied_recs_state_v3.json")
          r=json.load(open("artifacts/recommended_trades_v3.json"))
          asof=r.get("as_of_utc")
          skip = state.exists() and json.loads(state.read_text()).get("last_as_of_utc")==asof
          with open(os.environ["GITHUB_OUTPUT"],"a") as f:
              f.write(f"skip={str(skip).lower()}\n")
          print("as_of_utc:", asof, "skip:", skip)
          PY

      - name: Execute trades (paper portfolios)
        if: steps.idem.outputs.skip != 'true' && (github.event_name != 'workflow_dispatch' || github.event.inputs.dry_run != 'true')
        env:
          PRICES_FINAL:       data/prices_final.json
          TRADES_RECS:        artifacts/recommended_trades_v3.json
          TRADES_LEDGER:      data/trades_ledger.csv
          APPLY_TRADES:       "1"
          EXECUTE_SCOPE:      ${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.apply_personal == 'true') && 'both' || 'paper' }}
        run: |
          python scripts/update_performance_v3.py
          echo "---- Last 25 ledger lines ----"
          tail -n 25 data/trades_ledger.csv || true

      - name: Rebuild recs after execution (reflect new positions)
        if: steps.idem.outputs.skip != 'true' && (github.event_name != 'workflow_dispatch' || github.event.inputs.dry_run != 'true')
        env:
          INPUT_FINAL:        data/prices_final.json
          PORTFOLIOS_YML:     config/portfolios.yml
          OUT_WATCHLIST:      data/watchlist_summary.json
          OUT_TRADES:         artifacts/recommended_trades_v3.json
        run: python scripts/postprocess_v3.py

      - name: Mark snapshot as applied
        if: steps.idem.outputs.skip != 'true' && (github.event_name != 'workflow_dispatch' || github.event.inputs.dry_run != 'true')
        shell: bash
        run: |
          python - <<'PY'
          import json
          from pathlib import Path
          asof = json.load(open("artifacts/recommended_trades_v3.json")).get("as_of_utc")
          Path("data").mkdir(parents=True, exist_ok=True)
          Path("data/_applied_recs_state_v3.json").write_text(json.dumps({"last_as_of_utc": asof}, indent=2))
          print("marked", asof)
          PY

      - name: Update performance snapshots (final pass, no trades)
        env:
          PRICES_FINAL:       data/prices_final.json
          TRADES_RECS:        artifacts/recommended_trades_v3.json
          TRADES_LEDGER:      data/trades_ledger.csv
          APPLY_TRADES:       "0"
        run: python scripts/update_performance_v3.py

      - name: Build performance timeseries (+ charts)
        run: python scripts/build_perf_timeseries.py

      - name: Commit & push
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git pull --rebase --autostash origin ${{ github.ref_name }}
          git add -A artifacts data || true
          git commit -m "v3: persist per-portfolio artifacts (plans, ledgers, history, values) [skip ci]" || echo "No changes."
          git push
