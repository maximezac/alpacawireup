name: Gather + Execute (paper trades on)

on:
  workflow_dispatch:
    inputs:
      dry_run:
        description: "Dry run (no trade execution)"
        required: false
        default: "false"
      apply_personal:
        description: "Also apply trades to personal?"
        required: false
        default: "false"
  schedule:
    # ~30 min before US close (handles DST with two crons)
    - cron: "30 19 * * 1-5"
    - cron: "30 20 * * 1-5"

permissions:
  contents: write

concurrency:
  group: gather-exec-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas==2.2.2 numpy==1.26.4 requests==2.32.3 \
                      python-dateutil==2.9.0.post0 feedparser==6.0.11 \
                      vaderSentiment==3.3.2 pyyaml==6.0.2
          pip install -r requirements.txt || echo "requirements.txt already satisfied."

      - name: Probe freshness
        id: probe
        shell: bash
        run: |
          set -euo pipefail
          prices_final="data/prices_final.json"
          prices_base="data/prices.json"
          now=$(date +%s)
          fresh_prices=false
          fresh_base=false
          [[ -f "$prices_final" ]] && [[ $((now - $(stat -c %Y "$prices_final"))) -lt 600  ]] && fresh_prices=true
          [[ -f "$prices_base"  ]] && [[ $((now - $(stat -c %Y "$prices_base")))  -lt 3600 ]] && fresh_base=true
          {
            echo "fresh_prices=$fresh_prices"
            echo "fresh_base=$fresh_base"
          } >> "$GITHUB_OUTPUT"

      - name: Fetch prices (if stale)
        if: steps.probe.outputs.fresh_prices != 'true'
        env:
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          ALPACA_DATA_FEED:  iex
          SYMBOLS_PATH:      data/symbols.txt
          OUTPUT_PATH:       data/prices.json
          DAYS_BACK:         "270"
        run: python fetch_prices.py

      - name: Fetch news (if stale)
        if: steps.probe.outputs.fresh_base != 'true'
        env:
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          INPUT_PATH:        data/prices.json
          OUTPUT_PATH:       data/prices.json
          NEWS_LOOKBACK_DAYS: "7"
          NEWS_LIMIT_PER_SYMBOL: "25"
          NEWS_SOURCES: "benzinga,mtnewswires,google_rss,finnhub,reddit"
          NEWSAPI_KEY:       ${{ secrets.NEWSAPI_KEY }}
          FINNHUB_KEY:       ${{ secrets.FINNHUB_KEY }}
        run: python scripts/fetch_news.py

      - name: Generate enriched feed
        env:
          INPUT_PATH:  data/prices.json
          OUTPUT_PATH: data/prices_final.json
          MAX_ARTICLES: "15"
          DECAY_HALF_LIFE_HOURS: "12"
          SECTOR_NUDGE: "0.05"
          GENERATE_NOW: "1"
          ALPACA_KEY_ID:     ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
        run: python publish_feed.py

      - name: Postprocess (build multi-portfolio plans)
        env:
          INPUT_FINAL:        data/prices_final.json
          PORTFOLIOS_YML:     config/portfolios.yml
          OUT_WATCHLIST:      data/watchlist_summary.json
          OUT_TRADES:         artifacts/recommended_trades_v3.json
        run: |
          python scripts/postprocess_v3.py
          python - <<'PY'
          import json,sys
          try:
              obj=json.load(open("artifacts/recommended_trades_v3.json"))
              total=0
              for name,node in (obj.get("portfolios") or {}).items():
                  n=len(node.get("trades") or [])
                  print(f"- {name}: {n} trades")
                  total+=n
              print("TOTAL TRADES:", total)
          except Exception as e:
              print("summarize trades failed:", e, file=sys.stderr)
          PY

      - name: Inspect per-portfolio plans
        run: |
          echo "=== portfolios tree after postprocess ==="
          ls -R data/portfolios || true
          echo "=== sample contents ==="
          find data/portfolios -maxdepth 2 -type f -name 'trades_plan*.json' -print | head -n 30 || true


      - name: Check snapshot idempotency
        id: idem
        shell: bash
        run: |
          python - <<'PY'
          import os,json,sys
          from pathlib import Path
          state=Path("data/_applied_recs_state_v3.json")
          r=json.load(open("artifacts/recommended_trades_v3.json"))
          asof=r.get("as_of_utc")
          skip = state.exists() and json.loads(state.read_text()).get("last_as_of_utc")==asof
          with open(os.environ["GITHUB_OUTPUT"],"a") as f:
              f.write(f"skip={str(skip).lower()}\n")
          print("as_of_utc:", asof, "skip:", skip)
          PY

      - name: Execute trades (paper portfolios)
        if: steps.idem.outputs.skip != 'true' && (github.event_name != 'workflow_dispatch' || github.event.inputs.dry_run != 'true')
        env:
          PRICES_FINAL:       data/prices_final.json
          TRADES_RECS:        artifacts/recommended_trades_v3.json
          TRADES_LEDGER:      data/trades_ledger.csv
          APPLY_TRADES:       "1"
          EXECUTE_SCOPE:      ${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.apply_personal == 'true') && 'both' || 'paper' }}
        run: |
          python scripts/update_performance_v3.py
          echo "---- Last 25 ledger lines ----"
          tail -n 25 data/trades_ledger.csv || true

      - name: Rebuild recs after execution (reflect new positions)
        if: steps.idem.outputs.skip != 'true' && (github.event_name != 'workflow_dispatch' || github.event.inputs.dry_run != 'true')
        env:
          INPUT_FINAL:        data/prices_final.json
          PORTFOLIOS_YML:     config/portfolios.yml
          OUT_WATCHLIST:      data/watchlist_summary.json
          OUT_TRADES:         artifacts/recommended_trades_v3.json
        run: python scripts/postprocess_v3.py

      - name: Mark snapshot as applied
        if: steps.idem.outputs.skip != 'true' && (github.event_name != 'workflow_dispatch' || github.event.inputs.dry_run != 'true')
        shell: bash
        run: |
          python - <<'PY'
          import json
          from pathlib import Path
          asof = json.load(open("artifacts/recommended_trades_v3.json")).get("as_of_utc")
          Path("data").mkdir(parents=True, exist_ok=True)
          Path("data/_applied_recs_state_v3.json").write_text(json.dumps({"last_as_of_utc": asof}, indent=2))
          print("marked", asof)
          PY

      - name: Update performance snapshots (final pass, no trades)
        env:
          PRICES_FINAL:       data/prices_final.json
          TRADES_RECS:        artifacts/recommended_trades_v3.json
          TRADES_LEDGER:      data/trades_ledger.csv
          APPLY_TRADES:       "0"
        run: python scripts/update_performance_v3.py

      - name: Inspect per-portfolio outputs
        run: |
          echo "=== portfolios tree after update_performance ==="
          ls -R data/portfolios || true
          echo "=== sample files (value/applied/ledger/history) ==="
          find data/portfolios -type f \( \
            -name 'portfolio_value*.json' -o \
            -name 'trades_applied*.json' -o \
            -name 'trades_ledger.csv' -o \
            -name 'history.csv' -o \
            -name 'last_execution_summary.json' \
          \) -print | head -n 100 || true

      - name: Commit & push all portfolio data
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git pull --rebase --autostash origin ${{ github.ref_name }}

          # Stage artifacts + all nested portfolio outputs
          git add \
            artifacts/**/*.json artifacts/**/*.yaml artifacts/*.json artifacts/*.yaml \
            data/*.json data/*history.csv data/trades_ledger.csv data/watchlist_summary.json \
            data/portfolios/**

          # Optional: show whatâ€™s staged (for debugging)
          echo "=== staged files ==="
          git status --porcelain

          git commit -m "v3: persist per-portfolio artifacts (plans, ledgers, history, values) [skip ci]" || echo "No changes."
          git push


