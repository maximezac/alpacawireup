name: Gather Data (ideas only, no trades)

on:
  workflow_dispatch:
  push:
    paths:
      - "data/symbols.txt"
      - "fetch_prices.py"
      - "publish_feed.py"
      - "fetch_news.py"
      - "scripts/**"
      - "config/**"
      - ".github/workflows/**"
      - "requirements.txt"
  schedule:
    - cron: "0 * * * 1-5"  # every hour on weekdays

permissions:
  contents: write

# Prevent overlapping runs from double-hitting APIs
concurrency:
  group: gather-data-${{ github.ref }}
  cancel-in-progress: true

env:
  INPUT_PATH: data/prices.json
  INPUT_FINAL: data/prices_final.json
  OUTPUT_DIR: artifacts
  CONFIG_PORTFOLIOS: config/portfolios.yml
  CONFIG_STRATEGIES: config/strategies.yml

jobs:
  build-run-publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas==2.2.2 numpy==1.26.4 requests==2.32.3 vaderSentiment==3.3.2 python-dateutil==2.9.0.post0 feedparser==6.0.11
          pip install -r requirements.txt || echo "requirements.txt already satisfied."

      # ---------- Freshness probes to avoid duplicate API calls ----------
      - name: Probe freshness of prices_final.json and news
        id: probe
        shell: bash
        run: |
          prices_file="data/prices_final.json"
          news_file="data/prices.json"   # fetch_news updates this in-place

          now=$(date +%s)
          fresh_prices=false
          fresh_news=false

          # "fresh" == modified within last 10 minutes (prices) / 60 minutes (news)
          if [[ -f "$prices_file" ]]; then
            mtime=$(stat -c %Y "$prices_file")
            age=$((now - mtime))
            [[ $age -lt 600 ]] && fresh_prices=true
          fi
          if [[ -f "$news_file" ]]; then
            mtime=$(stat -c %Y "$news_file")
            age=$((now - mtime))
            [[ $age -lt 3600 ]] && fresh_news=true
          fi

          echo "fresh_prices=$fresh_prices" >> "$GITHUB_OUTPUT"
          echo "fresh_news=$fresh_news"     >> "$GITHUB_OUTPUT"

      # ---------- DATA FETCH ----------
      - name: Fetch prices from Alpaca (only if stale)
        if: steps.probe.outputs.fresh_prices != 'true'
        env:
          ALPACA_KEY_ID: ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          ALPACA_DATA_FEED: "iex"
          SYMBOLS_PATH: data/symbols.txt
          OUTPUT_PATH: ${{ env.INPUT_PATH }}
          DAYS_BACK: "270"
        run: python fetch_prices.py

      - name: Fetch news from Alpaca + extras (only if stale)
        if: steps.probe.outputs.fresh_news != 'true'
        env:
          ALPACA_KEY_ID: ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          INPUT_PATH: ${{ env.INPUT_PATH }}
          OUTPUT_PATH: ${{ env.INPUT_PATH }}   # in-place
          NEWS_LOOKBACK_DAYS: "7"
          NEWS_LIMIT_PER_SYMBOL: "25"
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}   # optional
          FINNHUB_KEY: ${{ secrets.FINNHUB_KEY }}   # optional
          NEWS_SOURCES: "benzinga,mtnewswires,google_rss,finnhub,reddit"
        run: python fetch_news.py

      - name: Generate enriched feed (skip API if already fresh; always compute)
        env:
          INPUT_PATH: ${{ env.INPUT_PATH }}
          OUTPUT_PATH: ${{ env.INPUT_FINAL }}
          MAX_ARTICLES: "15"
          DECAY_HALF_LIFE_HOURS: "12"
          SECTOR_NUDGE: "0.05"
          GENERATE_NOW: "1"
          ALPACA_KEY_ID: ${{ secrets.ALPACA_KEY_ID }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
        run: python publish_feed.py

      # ---------- POSTPROCESS (ideas only; no execution) ----------
      - name: Build recs for all portfolios (v3)
        env:
          INPUT_FINAL: ${{ env.INPUT_FINAL }}
          CONFIG_PORTFOLIOS: ${{ env.CONFIG_PORTFOLIOS }}
          CONFIG_STRATEGIES: ${{ env.CONFIG_STRATEGIES }}
          OUTPUT_DIR: ${{ env.OUTPUT_DIR }}
        run: python scripts/postprocess_v3.py

      - name: Summarize recs (counts per portfolio)
        run: |
          python -c "import json; obj=json.load(open('artifacts/recommended_trades.json')); tot=0; [print(f'- {n}: {len(k.get(\"trades\") or [])} trades') or (tot:=tot+len(k.get('trades') or [])) for n,k in (obj.get('portfolios') or {}).items()]; print('TOTAL TRADES:', tot)"

      - name: Update performance snapshots (NO trades)
        env:
          PRICES_FINAL: ${{ env.INPUT_FINAL }}
          PORTFOLIO_PAPER_CSV: data/portfolio_paper.csv
          PORTFOLIO_PERSONAL_CSV: data/portfolio_personal.csv
          HISTORY_PAPER: data/portfolio_paper_history.csv
          HISTORY_PERSONAL: data/portfolio_personal_history.csv
          TRADES_RECS: artifacts/recommended_trades.json
          TRADES_LEDGER: data/trades_ledger.csv
          APPLY_TRADES: "0"                   # <- ideas-only
          APPLY_PAPER_TRADES: "0"
          APPLY_PERSONAL_TRADES: "0"
          SLIPPAGE_BPS_PAPER: "10"
          SLIPPAGE_BPS_PERSONAL: "5"
          LIQ_IMPACT_BPS_SMALLCAP: "5"
          SMALLCAPS: "QBTS,QUBT,RGTI,ASTS,RKLB,SOFI"
        run: python scripts/update_performance.py

      - name: Commit & push artifacts (single commit)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git pull --rebase --autostash origin ${{ github.ref_name }}
          git add \
            data/prices.json data/prices_final.json \
            artifacts/**/*.json artifacts/*.json \
            data/portfolio_*.csv data/*history.csv data/trades_ledger.csv data/perf_summary_*.json
          git commit -m "chore: refresh prices, multi-portfolio recs (ideas-only, v3)" || echo "No changes to commit."
          git push
